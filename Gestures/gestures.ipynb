{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06dd1885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dollarpy in c:\\users\\omar3\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dollarpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7f05c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv\n",
    "from dollarpy import Recognizer, Template, Point\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9b9102ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates=[] #list of templates for $1 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3a95a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoints(videoURL,label):\n",
    "    cap = cv2.VideoCapture(videoURL)#web cam =0 , else enter filename\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        points = []\n",
    "        wrist = [] \n",
    "        Thumb_cmc=[]\n",
    "        Thumb_mcp=[]\n",
    "        Thumb_ip=[]\n",
    "        Thumb_tip=[]\n",
    "        Index_finger_mcp=[]\n",
    "        Index_finger_pip=[]\n",
    "        Index_finger_dip=[]\n",
    "        Index_finger_tip=[]\n",
    "        Middle_finger_mcp=[]\n",
    "        Middle_finger_pip=[]\n",
    "        Middle_finger_dip=[]\n",
    "        Middle_finger_tip=[]\n",
    "        Ring_finger_mcp=[]\n",
    "        Ring_finger_pip=[]\n",
    "        Ring_finger_dip=[]\n",
    "        Ring_finger_tip=[]\n",
    "        Pinky_mcp=[]\n",
    "        Pinky_pip=[]\n",
    "        Pinky_dip=[]\n",
    "        Pinky_tip=[]\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor Feed\n",
    "            if ret==True:\n",
    "\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Drawing on Frame (You can remove it)\n",
    "                # 2. Right hand\n",
    "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                # # 4. Pose Detections\n",
    "                # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                # # Export coordinates\n",
    "\n",
    "                try:\n",
    "\n",
    "                    # add points of wrist , elbow and shoulder\n",
    "                    wrist.append(Point(results.pose_landmarks.landmark[0].x,results.pose_landmarks.landmark[0].y,1))\n",
    "                    Thumb_cmc.append(Point(results.pose_landmarks.landmark[1].x,results.pose_landmarks.landmark[1].y,1))\n",
    "                    Thumb_mcp.append(Point(results.pose_landmarks.landmark[2].x,results.pose_landmarks.landmark[2].y,1))\n",
    "                    Thumb_ip .append(Point(results.pose_landmarks.landmark[3].x,results.pose_landmarks.landmark[3].y,1))\n",
    "                    Thumb_tip .append(Point(results.pose_landmarks.landmark[4].x,results.pose_landmarks.landmark[4].y,1))\n",
    "                    Index_finger_mcp.append(Point(results.pose_landmarks.landmark[5].x,results.pose_landmarks.landmark[5].y,1))\n",
    "                    Index_finger_pip.append(Point(results.pose_landmarks.landmark[6].x,results.pose_landmarks.landmark[6].y,1))\n",
    "                    Index_finger_dip.append(Point(results.pose_landmarks.landmark[7].x,results.pose_landmarks.landmark[7].y,1))\n",
    "                    Index_finger_tip.append(Point(results.pose_landmarks.landmark[8].x,results.pose_landmarks.landmark[8].y,1))\n",
    "                    Middle_finger_mcp.append(Point(results.pose_landmarks.landmark[9].x,results.pose_landmarks.landmark[9].y,1))\n",
    "                    Middle_finger_pip.append(Point(results.pose_landmarks.landmark[10].x,results.pose_landmarks.landmark[10].y,1))\n",
    "                    Middle_finger_dip.append(Point(results.pose_landmarks.landmark[11].x,results.pose_landmarks.landmark[11].y,1))\n",
    "                    Middle_finger_tip.append(Point(results.pose_landmarks.landmark[12].x,results.pose_landmarks.landmark[12].y,1))\n",
    "                    Ring_finger_mcp.append(Point(results.pose_landmarks.landmark[13].x,results.pose_landmarks.landmark[13].y,1))\n",
    "                    Ring_finger_pip.append(Point(results.pose_landmarks.landmark[14].x,results.pose_landmarks.landmark[14].y,1))\n",
    "                    Ring_finger_dip.append(Point(results.pose_landmarks.landmark[15].x,results.pose_landmarks.landmark[15].y,1))\n",
    "                    Ring_finger_tip.append(Point(results.pose_landmarks.landmark[16].x,results.pose_landmarks.landmark[16].y,1))\n",
    "                    Pinky_mcp.append(Point(results.pose_landmarks.landmark[17].x,results.pose_landmarks.landmark[17].y,1))\n",
    "                    Pinky_pip.append(Point(results.pose_landmarks.landmark[18].x,results.pose_landmarks.landmark[18].y,1))\n",
    "                    Pinky_dip.append(Point(results.pose_landmarks.landmark[19].x,results.pose_landmarks.landmark[19].y,1))\n",
    "                    Pinky_tip.append(Point(results.pose_landmarks.landmark[20].x,results.pose_landmarks.landmark[20].y,1))\n",
    "\n",
    "\n",
    "\n",
    "                except:  \n",
    "                    pass\n",
    "\n",
    "                cv2.imshow(label, image)\n",
    "            else :\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(100)\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(100)\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    points = wrist + Thumb_cmc + Thumb_mcp + Thumb_ip + Thumb_tip + Index_finger_mcp + Index_finger_pip + Index_finger_dip + Index_finger_tip + Middle_finger_mcp + Middle_finger_pip + Middle_finger_dip + Middle_finger_tip + Ring_finger_mcp + Ring_finger_pip + Ring_finger_dip + Ring_finger_tip + Pinky_mcp + Pinky_pip + Pinky_dip + Pinky_tip\n",
    "    print(label)\n",
    "    return points\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f31106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8540eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid = \"c:\\\\Users\\\\Abdelelah Hazem\\\\Downloads\\\\Gestures.mp4\"\n",
    "# points = getPoints(vid,\"Correct Hook Execution\") \n",
    "# points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5b85c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "65629e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save templates with pickle\n",
    "def save_templates(templates, filename=\"templates.pkl\"):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(templates, f)\n",
    "    print(f\"Templates saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9786dddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map\n",
      "Traffic\n",
      "Bus\n",
      "Train\n",
      "zoom in\n",
      "zoom out\n",
      "Templates saved to templates.pkl\n"
     ]
    }
   ],
   "source": [
    "#hook wrong correct\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\Map 2.mp4\"\n",
    "# vid = \"C:\\\\Users\\Abdelelah Hazem\\\\Downloads\\\\Map.mp4\"\n",
    "points = getPoints(vid,\"Map\") \n",
    "tmpl_2 = Template('Map', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "#hook no defense no torso twist\n",
    "# vid = \"Dataset/hook/hook wrong no torso twist no defence .mp4\"\n",
    "# points = getPoints(vid,\"hook wrong no torso twist no defence\") \n",
    "# tmpl_2 = Template('hook wrong no torso twist no defence', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "#hook wrong no torso twist \n",
    "# vid = \"C:\\Users\\omar3\\Pictures\\Camera Roll\\Traffic.mp4\"\n",
    "# points = getPoints(vid,\"hook wrong no torso twist\") \n",
    "# tmpl_2 = Template('hook wrong no torso twist', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "# #hook wrong no defense\n",
    "# vid = \"C:\\Users\\omar3\\Pictures\\Camera Roll\\Bus.mp4\"\n",
    "# points = getPoints(vid,\"hook wrong no defence\") \n",
    "# tmpl_2 = Template('hook wrong no defence', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "templates2 = []\n",
    "\n",
    "\n",
    "\n",
    "#UPPER\n",
    "#uppercut correct\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\Traffic 2.mp4\"\n",
    "# vid = \"C:\\\\Users\\\\Abdelelah Hazem\\\\Downloads\\\\Traffic.mp4\"\n",
    "points = getPoints(vid,\"Traffic\") \n",
    "tmpl_2 = Template('Traffic', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "# #uppercut wrong (no torso & ankle  twist)\n",
    "# vid = \"C:\\Users\\omar3\\Pictures\\Camera Roll\\.mp4\"\n",
    "# points = getPoints(vid,\"uppercut wrong (no torso & ankle  twist)\") \n",
    "# tmpl_2 = Template('uppercut wrong (no torso & ankle  twist)', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "# #uppercut wrong no defence\n",
    "# vid = \"C:\\Users\\omar3\\Pictures\\Camera Roll\\.mp4\"\n",
    "# points = getPoints(vid,\"uppercut wrong no defence\") \n",
    "# tmpl_2 = Template('uppercut wrong no defence', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#right stroke wrong no defence\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\Bus 2.mp4\"\n",
    "# vid = \"C:\\\\Users\\\\Abdelelah Hazem\\\\Downloads\\\\Bus.mov\"\n",
    "points = getPoints(vid,\"Bus\") \n",
    "tmpl_2 = Template('Bus', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "# #right stroke wrong hand down no torso twist\n",
    "# vid = \"Dataset/right/(right) hand down no torso twist.mp4\"\n",
    "# points = getPoints(vid,\"(right) hand down no torso twist\") \n",
    "# tmpl_2 = Template('(right) hand down no torso twist', points)\n",
    "# templates.append(tmpl_2)\n",
    "# #right wrong  wrong return\n",
    "# vid = \"Dataset/right/(right) wrong return.mp4\"\n",
    "# points = getPoints(vid,\"(right) wrong return\") \n",
    "# tmpl_2 = Template('(right) wrong return', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#right stroke wrong no defence\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\Train.mp4\"\n",
    "# vid = \"c:\\\\Users\\Abdelelah Hazem\\\\Downloads\\\\Train.mp4\"\n",
    "points = getPoints(vid,\"Train\") \n",
    "tmpl_2 = Template('Train', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\zoom in 3.mp4\"\n",
    "# vid = \"c:\\\\Users\\Abdelelah Hazem\\\\Downloads\\\\Train.mp4\"\n",
    "points = getPoints(vid,\"zoom in\") \n",
    "tmpl_2 = Template('zoom in', points)\n",
    "# templates.append(tmpl_2)\n",
    "templates2.append(tmpl_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\zoom out 2.mp4\"\n",
    "# vid = \"c:\\\\Users\\Abdelelah Hazem\\\\Downloads\\\\Train.mp4\"\n",
    "points = getPoints(vid,\"zoom out\") \n",
    "tmpl_2 = Template('zoom out', points)\n",
    "# templates.append(tmpl_2)\n",
    "templates2.append(tmpl_2)\n",
    "save_templates(templates)\n",
    "#[]\n",
    "# #right stroke wrong hand down no torso twist\n",
    "# vid = \"Dataset/right/(right) hand down no torso twist.mp4\"\n",
    "# points = getPoints(vid,\"(right) hand down no torso twist\") \n",
    "# tmpl_2 = Template('(right) hand down no torso twist', points)\n",
    "# templates.append(tmpl_2)\n",
    "# #right wrong  wrong return\n",
    "# vid = \"Dataset/right/(right) wrong return.mp4\"\n",
    "# points = getPoints(vid,\"(right) wrong return\") \n",
    "# tmpl_2 = Template('(right) wrong return', points)\n",
    "# templates.append(tmpl_2)\n",
    "recognizer = Recognizer(templates)\n",
    "recognizer2 = Recognizer(templates2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def testpoints():\n",
    "#     cap = cv2.VideoCapture(1)#web cam =0 , else enter filename\n",
    "#     # Initiate holistic model\n",
    "#     with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#         points = []\n",
    "#         wrist = []\n",
    "#         Thumb_cmc=[]\n",
    "#         Thumb_mcp=[]\n",
    "#         Thumb_ip=[]\n",
    "#         Thumb_tip=[]\n",
    "#         Index_finger_mcp=[]\n",
    "#         Index_finger_pip=[]\n",
    "#         Index_finger_dip=[]\n",
    "#         Index_finger_tip=[]\n",
    "#         Middle_finger_mcp=[]\n",
    "#         Middle_finger_pip=[]\n",
    "#         Middle_finger_dip=[]\n",
    "#         Middle_finger_tip=[]\n",
    "#         Ring_finger_mcp=[]\n",
    "#         Ring_finger_pip=[]\n",
    "#         Ring_finger_dip=[]\n",
    "#         Ring_finger_tip=[]\n",
    "#         Pinky_mcp=[]\n",
    "#         Pinky_pip=[]\n",
    "#         Pinky_dip=[]\n",
    "#         Pinky_tip=[]   \n",
    "\n",
    "#         while cap.isOpened():\n",
    "#             # time.sleep(0.2)\n",
    "#             ret, frame = cap.read()\n",
    "\n",
    "#             # Recolor Feed\n",
    "#             if ret==True:\n",
    "\n",
    "#                 image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#                 image.flags.writeable = False        \n",
    "\n",
    "#                 # Make Detections\n",
    "#                 results = holistic.process(image)\n",
    "#                 # print(results.face_landmarks)\n",
    "\n",
    "\n",
    "#                 # Recolor image back to BGR for rendering\n",
    "#                 image.flags.writeable = True   \n",
    "#                 image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#                 # Drawing on Frame (You can remove it)\n",
    "#                 # 2. Right hand\n",
    "#                 mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "#                 # 3. Left Hand\n",
    "#                 mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "#                 # # 4. Pose Detections\n",
    "#                 # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "#                 # # Export coordinates\n",
    "\n",
    "#                 try:\n",
    "\n",
    "#                     # add points of wrist , elbow and shoulder\n",
    "#                     wrist.append(Point(results.pose_landmarks.landmark[0].x,results.pose_landmarks.landmark[0].y,1))\n",
    "#                     Thumb_cmc.append(Point(results.pose_landmarks.landmark[1].x,results.pose_landmarks.landmark[1].y,1))\n",
    "#                     Thumb_mcp.append(Point(results.pose_landmarks.landmark[2].x,results.pose_landmarks.landmark[2].y,1))\n",
    "#                     Thumb_ip .append(Point(results.pose_landmarks.landmark[3].x,results.pose_landmarks.landmark[3].y,1))\n",
    "#                     Thumb_tip .append(Point(results.pose_landmarks.landmark[4].x,results.pose_landmarks.landmark[4].y,1))\n",
    "#                     Index_finger_mcp.append(Point(results.pose_landmarks.landmark[5].x,results.pose_landmarks.landmark[5].y,1))\n",
    "#                     Index_finger_pip.append(Point(results.pose_landmarks.landmark[6].x,results.pose_landmarks.landmark[6].y,1))\n",
    "#                     Index_finger_dip.append(Point(results.pose_landmarks.landmark[7].x,results.pose_landmarks.landmark[7].y,1))\n",
    "#                     Index_finger_tip.append(Point(results.pose_landmarks.landmark[8].x,results.pose_landmarks.landmark[8].y,1))\n",
    "#                     Middle_finger_mcp.append(Point(results.pose_landmarks.landmark[9].x,results.pose_landmarks.landmark[9].y,1))\n",
    "#                     Middle_finger_pip.append(Point(results.pose_landmarks.landmark[10].x,results.pose_landmarks.landmark[10].y,1))\n",
    "#                     Middle_finger_dip.append(Point(results.pose_landmarks.landmark[11].x,results.pose_landmarks.landmark[11].y,1))\n",
    "#                     Middle_finger_tip.append(Point(results.pose_landmarks.landmark[12].x,results.pose_landmarks.landmark[12].y,1))\n",
    "#                     Ring_finger_mcp.append(Point(results.pose_landmarks.landmark[13].x,results.pose_landmarks.landmark[13].y,1))\n",
    "#                     Ring_finger_pip.append(Point(results.pose_landmarks.landmark[14].x,results.pose_landmarks.landmark[14].y,1))\n",
    "#                     Ring_finger_dip.append(Point(results.pose_landmarks.landmark[15].x,results.pose_landmarks.landmark[15].y,1))\n",
    "#                     Ring_finger_tip.append(Point(results.pose_landmarks.landmark[16].x,results.pose_landmarks.landmark[16].y,1))\n",
    "#                     Pinky_mcp.append(Point(results.pose_landmarks.landmark[17].x,results.pose_landmarks.landmark[17].y,1))\n",
    "#                     Pinky_pip.append(Point(results.pose_landmarks.landmark[18].x,results.pose_landmarks.landmark[18].y,1))\n",
    "#                     Pinky_dip.append(Point(results.pose_landmarks.landmark[19].x,results.pose_landmarks.landmark[19].y,1))\n",
    "#                     Pinky_tip.append(Point(results.pose_landmarks.landmark[20].x,results.pose_landmarks.landmark[20].y,1))\n",
    "#                     points = wrist + Thumb_cmc + Thumb_mcp + Thumb_ip + Thumb_tip + Index_finger_mcp + Index_finger_pip + Index_finger_dip + Index_finger_tip + Middle_finger_mcp + Middle_finger_pip + Middle_finger_dip + Middle_finger_tip + Ring_finger_mcp + Ring_finger_pip + Ring_finger_dip + Ring_finger_tip + Pinky_mcp + Pinky_pip + Pinky_dip + Pinky_tip\n",
    "#                     result = recognizer.recognize(points)\n",
    "#                     cv2.putText(image, f\"{result[0]} {result[1]}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "#                     # print(result)\n",
    "\n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "#                 cv2.imshow('aaa', image)\n",
    "#             else :\n",
    "#                 cap.release()\n",
    "#                 cv2.destroyAllWindows()\n",
    "#                 cv2.waitKey(100)\n",
    "#                 break\n",
    "\n",
    "#             if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#                 cap.release()\n",
    "#                 cv2.destroyAllWindows()\n",
    "#                 cv2.waitKey(100)\n",
    "#                 break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# testpoints()\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def testpoints():\n",
    "#     cap = cv2.VideoCapture(1)  # web cam = 0, else enter filename\n",
    "\n",
    "#     # Initiate holistic model\n",
    "#     with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#         frames_buffer = []  # Buffer to hold the frames\n",
    "#         points_buffer = []  # Buffer to hold points of 20 frames\n",
    "\n",
    "#         while cap.isOpened():\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret:\n",
    "#                 cap.release()\n",
    "#                 cv2.destroyAllWindows()\n",
    "#                 cv2.waitKey(100)\n",
    "#                 break\n",
    "\n",
    "#             # Convert color and make non-writable for performance\n",
    "#             image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             image.flags.writeable = False\n",
    "\n",
    "#             # Make detections\n",
    "#             results = holistic.process(image)\n",
    "#             image.flags.writeable = True\n",
    "#             image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#             # Drawing landmarks (optional)\n",
    "#             mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "#             mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "#             try:\n",
    "#                 # Extracting landmarks for the hand and storing points\n",
    "#                 current_frame_points = []\n",
    "#                 for i in range(21):  # 21 landmarks for a hand\n",
    "#                     lm = results.right_hand_landmarks.landmark[i]\n",
    "#                     current_frame_points.append(Point(lm.x, lm.y, 1))  # Add landmarks\n",
    "\n",
    "#                 points_buffer.append(current_frame_points)  # Add points to buffer\n",
    "#             except:\n",
    "#                 pass  # If no landmarks are detected\n",
    "\n",
    "#             # Process gesture every 15 frames\n",
    "#             if len(points_buffer) == 15:\n",
    "#                 # Combine all points from the buffer for gesture recognition\n",
    "#                 all_points = [point for frame in points_buffer for point in frame]\n",
    "#                 result = recognizer.recognize(all_points)  # Perform gesture recognition\n",
    "#                 cv2.putText(image, f\"{result[0]} {result[1]}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "#                 points_buffer.clear()  # Reset buffer after processing\n",
    "\n",
    "#             # Show the frame\n",
    "#             cv2.imshow('Gesture Recognition', image)\n",
    "\n",
    "#             # Quit on 'q' key press\n",
    "#             if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "# testpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a45499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testpoints():\n",
    "    cap = cv2.VideoCapture(1)#web cam =0 , else enter filename\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        points = []\n",
    "        wrist = []\n",
    "        Thumb_cmc=[]\n",
    "        Thumb_mcp=[]\n",
    "        Thumb_ip=[]\n",
    "        Thumb_tip=[]\n",
    "        Index_finger_mcp=[]\n",
    "        Index_finger_pip=[]\n",
    "        Index_finger_dip=[]\n",
    "        Index_finger_tip=[]\n",
    "        Middle_finger_mcp=[]\n",
    "        Middle_finger_pip=[]\n",
    "        Middle_finger_dip=[]\n",
    "        Middle_finger_tip=[]\n",
    "        Ring_finger_mcp=[]\n",
    "        Ring_finger_pip=[]\n",
    "        Ring_finger_dip=[]\n",
    "        Ring_finger_tip=[]\n",
    "        Pinky_mcp=[]\n",
    "        Pinky_pip=[]\n",
    "        Pinky_dip=[]\n",
    "        Pinky_tip=[]   \n",
    "        frames_buffer = []  # Buffer to hold the frames\n",
    "        points_buffer = []  # Buffer to hold points of 20 frames\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor Feed\n",
    "            if ret==True:\n",
    "\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Drawing on Frame (You can remove it)\n",
    "                # 2. Right hand\n",
    "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                # # 4. Pose Detections\n",
    "                # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                # # Export coordinates\n",
    "\n",
    "                try:\n",
    "\n",
    "                    # add points of wrist , elbow and shoulder\n",
    "                    wrist.append(Point(results.pose_landmarks.landmark[0].x,results.pose_landmarks.landmark[0].y,1))\n",
    "                    Thumb_cmc.append(Point(results.pose_landmarks.landmark[1].x,results.pose_landmarks.landmark[1].y,1))\n",
    "                    Thumb_mcp.append(Point(results.pose_landmarks.landmark[2].x,results.pose_landmarks.landmark[2].y,1))\n",
    "                    Thumb_ip .append(Point(results.pose_landmarks.landmark[3].x,results.pose_landmarks.landmark[3].y,1))\n",
    "                    Thumb_tip .append(Point(results.pose_landmarks.landmark[4].x,results.pose_landmarks.landmark[4].y,1))\n",
    "                    Index_finger_mcp.append(Point(results.pose_landmarks.landmark[5].x,results.pose_landmarks.landmark[5].y,1))\n",
    "                    Index_finger_pip.append(Point(results.pose_landmarks.landmark[6].x,results.pose_landmarks.landmark[6].y,1))\n",
    "                    Index_finger_dip.append(Point(results.pose_landmarks.landmark[7].x,results.pose_landmarks.landmark[7].y,1))\n",
    "                    Index_finger_tip.append(Point(results.pose_landmarks.landmark[8].x,results.pose_landmarks.landmark[8].y,1))\n",
    "                    Middle_finger_mcp.append(Point(results.pose_landmarks.landmark[9].x,results.pose_landmarks.landmark[9].y,1))\n",
    "                    Middle_finger_pip.append(Point(results.pose_landmarks.landmark[10].x,results.pose_landmarks.landmark[10].y,1))\n",
    "                    Middle_finger_dip.append(Point(results.pose_landmarks.landmark[11].x,results.pose_landmarks.landmark[11].y,1))\n",
    "                    Middle_finger_tip.append(Point(results.pose_landmarks.landmark[12].x,results.pose_landmarks.landmark[12].y,1))\n",
    "                    Ring_finger_mcp.append(Point(results.pose_landmarks.landmark[13].x,results.pose_landmarks.landmark[13].y,1))\n",
    "                    Ring_finger_pip.append(Point(results.pose_landmarks.landmark[14].x,results.pose_landmarks.landmark[14].y,1))\n",
    "                    Ring_finger_dip.append(Point(results.pose_landmarks.landmark[15].x,results.pose_landmarks.landmark[15].y,1))\n",
    "                    Ring_finger_tip.append(Point(results.pose_landmarks.landmark[16].x,results.pose_landmarks.landmark[16].y,1))\n",
    "                    Pinky_mcp.append(Point(results.pose_landmarks.landmark[17].x,results.pose_landmarks.landmark[17].y,1))\n",
    "                    Pinky_pip.append(Point(results.pose_landmarks.landmark[18].x,results.pose_landmarks.landmark[18].y,1))\n",
    "                    Pinky_dip.append(Point(results.pose_landmarks.landmark[19].x,results.pose_landmarks.landmark[19].y,1))\n",
    "                    Pinky_tip.append(Point(results.pose_landmarks.landmark[20].x,results.pose_landmarks.landmark[20].y,1))\n",
    "                    points = wrist + Thumb_cmc + Thumb_mcp + Thumb_ip + Thumb_tip + Index_finger_mcp + Index_finger_pip + Index_finger_dip + Index_finger_tip + Middle_finger_mcp + Middle_finger_pip + Middle_finger_dip + Middle_finger_tip + Ring_finger_mcp + Ring_finger_pip + Ring_finger_dip + Ring_finger_tip + Pinky_mcp + Pinky_pip + Pinky_dip + Pinky_tip\n",
    "                    points_buffer.append(points)                    \n",
    "\n",
    "                    result = recognizer.recognize(points)\n",
    "                    result2 = []\n",
    "                    all_points = []\n",
    "                    if len(points_buffer) == 15:\n",
    "                        for frame in points_buffer:\n",
    "                            for point in frame:\n",
    "                                all_points.append(point)\n",
    "                        if len(all_points) > 0:               \n",
    "                            result2 = recognizer2.recognize(all_points)\n",
    "                            if result[0] != None and result2[0] == None :\n",
    "                                cv2.putText(image, f\"{result[0]} {result[1]}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                            elif result2[0] != None:\n",
    "                                cv2.putText(image, f\"{result2[0]} {result2[1]}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                            points_buffer = []\n",
    "                            all_points = []\n",
    "                        # print(result)\n",
    "                    else:\n",
    "                        if result != None:\n",
    "                            cv2.putText(image, f\"{result[0]} {result[1]}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                cv2.imshow('aaa', image)\n",
    "            else :\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(100)\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(100)\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "testpoints()\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f67f338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0bca825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Determine Points (Create empty list/s)\n",
    "# 2- Reshape Meidapipe format into Point Format (append to list)\n",
    "# 3- Record Dataset (3 Circle,3 Rectangle ,3 Square) via thumb\n",
    "# 3- Record Dataset (3 Circle,3 Rectangle ,3 Square) via index\n",
    "# 4- Training (2 samples for each class) via thumb\n",
    "# 4- Training (2 samples for each class) via index\n",
    "# 5- Testing (1 sample for each class) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
