{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "06dd1885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dollarpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7f05c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv\n",
    "from dollarpy import Recognizer, Template, Point\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9b9102ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates=[] #list of templates for $1 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3a95a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoints(videoURL,label):\n",
    "    cap = cv2.VideoCapture(videoURL)#web cam =0 , else enter filename\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        points = []\n",
    "        wrist = [] \n",
    "        Thumb_cmc=[]\n",
    "        Thumb_mcp=[]\n",
    "        Thumb_ip=[]\n",
    "        Thumb_tip=[]\n",
    "        Index_finger_mcp=[]\n",
    "        Index_finger_pip=[]\n",
    "        Index_finger_dip=[]\n",
    "        Index_finger_tip=[]\n",
    "        Middle_finger_mcp=[]\n",
    "        Middle_finger_pip=[]\n",
    "        Middle_finger_dip=[]\n",
    "        Middle_finger_tip=[]\n",
    "        Ring_finger_mcp=[]\n",
    "        Ring_finger_pip=[]\n",
    "        Ring_finger_dip=[]\n",
    "        Ring_finger_tip=[]\n",
    "        Pinky_mcp=[]\n",
    "        Pinky_pip=[]\n",
    "        Pinky_dip=[]\n",
    "        Pinky_tip=[]\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor Feed\n",
    "            if ret==True:\n",
    "\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Drawing on Frame (You can remove it)\n",
    "                # 2. Right hand\n",
    "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                # # 4. Pose Detections\n",
    "                # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                # # Export coordinates\n",
    "\n",
    "                try:\n",
    "\n",
    "                    # add points of wrist , elbow and shoulder\n",
    "                    wrist.append(Point(results.pose_landmarks.landmark[0].x,results.pose_landmarks.landmark[0].y,1))\n",
    "                    Thumb_cmc.append(Point(results.pose_landmarks.landmark[1].x,results.pose_landmarks.landmark[1].y,1))\n",
    "                    Thumb_mcp.append(Point(results.pose_landmarks.landmark[2].x,results.pose_landmarks.landmark[2].y,1))\n",
    "                    Thumb_ip .append(Point(results.pose_landmarks.landmark[3].x,results.pose_landmarks.landmark[3].y,1))\n",
    "                    Thumb_tip .append(Point(results.pose_landmarks.landmark[4].x,results.pose_landmarks.landmark[4].y,1))\n",
    "                    Index_finger_mcp.append(Point(results.pose_landmarks.landmark[5].x,results.pose_landmarks.landmark[5].y,1))\n",
    "                    Index_finger_pip.append(Point(results.pose_landmarks.landmark[6].x,results.pose_landmarks.landmark[6].y,1))\n",
    "                    Index_finger_dip.append(Point(results.pose_landmarks.landmark[7].x,results.pose_landmarks.landmark[7].y,1))\n",
    "                    Index_finger_tip.append(Point(results.pose_landmarks.landmark[8].x,results.pose_landmarks.landmark[8].y,1))\n",
    "                    Middle_finger_mcp.append(Point(results.pose_landmarks.landmark[9].x,results.pose_landmarks.landmark[9].y,1))\n",
    "                    Middle_finger_pip.append(Point(results.pose_landmarks.landmark[10].x,results.pose_landmarks.landmark[10].y,1))\n",
    "                    Middle_finger_dip.append(Point(results.pose_landmarks.landmark[11].x,results.pose_landmarks.landmark[11].y,1))\n",
    "                    Middle_finger_tip.append(Point(results.pose_landmarks.landmark[12].x,results.pose_landmarks.landmark[12].y,1))\n",
    "                    Ring_finger_mcp.append(Point(results.pose_landmarks.landmark[13].x,results.pose_landmarks.landmark[13].y,1))\n",
    "                    Ring_finger_pip.append(Point(results.pose_landmarks.landmark[14].x,results.pose_landmarks.landmark[14].y,1))\n",
    "                    Ring_finger_dip.append(Point(results.pose_landmarks.landmark[15].x,results.pose_landmarks.landmark[15].y,1))\n",
    "                    Ring_finger_tip.append(Point(results.pose_landmarks.landmark[16].x,results.pose_landmarks.landmark[16].y,1))\n",
    "                    Pinky_mcp.append(Point(results.pose_landmarks.landmark[17].x,results.pose_landmarks.landmark[17].y,1))\n",
    "                    Pinky_pip.append(Point(results.pose_landmarks.landmark[18].x,results.pose_landmarks.landmark[18].y,1))\n",
    "                    Pinky_dip.append(Point(results.pose_landmarks.landmark[19].x,results.pose_landmarks.landmark[19].y,1))\n",
    "                    Pinky_tip.append(Point(results.pose_landmarks.landmark[20].x,results.pose_landmarks.landmark[20].y,1))\n",
    "\n",
    "\n",
    "\n",
    "                except:  \n",
    "                    pass\n",
    "\n",
    "                cv2.imshow(label, image)\n",
    "            else :\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(100)\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(100)\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    points = wrist + Thumb_cmc + Thumb_mcp + Thumb_ip + Thumb_tip + Index_finger_mcp + Index_finger_pip + Index_finger_dip + Index_finger_tip + Middle_finger_mcp + Middle_finger_pip + Middle_finger_dip + Middle_finger_tip + Ring_finger_mcp + Ring_finger_pip + Ring_finger_dip + Ring_finger_tip + Pinky_mcp + Pinky_pip + Pinky_dip + Pinky_tip\n",
    "    print(label)\n",
    "    return points\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f31106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8540eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid = \"c:\\\\Users\\\\Abdelelah Hazem\\\\Downloads\\\\Gestures.mp4\"\n",
    "# points = getPoints(vid,\"Correct Hook Execution\") \n",
    "# points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5b85c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "65629e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save templates with pickle\n",
    "# def save_templates(templates, filename=\"templates.pkl\"):\n",
    "#     with open(filename, 'wb') as f:\n",
    "#         pickle.dump(templates, f)\n",
    "#     print(f\"Templates saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9786dddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map\n",
      "Traffic\n",
      "Bus\n",
      "Train\n"
     ]
    }
   ],
   "source": [
    "#hook wrong correct\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\Map 2.mp4\"\n",
    "# vid = \"C:\\\\Users\\Abdelelah Hazem\\\\Downloads\\\\Map.mp4\"\n",
    "points = getPoints(vid,\"Map\") \n",
    "tmpl_2 = Template('Map', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "#hook no defense no torso twist\n",
    "# vid = \"Dataset/hook/hook wrong no torso twist no defence .mp4\"\n",
    "# points = getPoints(vid,\"hook wrong no torso twist no defence\") \n",
    "# tmpl_2 = Template('hook wrong no torso twist no defence', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "#hook wrong no torso twist \n",
    "# vid = \"C:\\Users\\omar3\\Pictures\\Camera Roll\\Traffic.mp4\"\n",
    "# points = getPoints(vid,\"hook wrong no torso twist\") \n",
    "# tmpl_2 = Template('hook wrong no torso twist', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "# #hook wrong no defense\n",
    "# vid = \"C:\\Users\\omar3\\Pictures\\Camera Roll\\Bus.mp4\"\n",
    "# points = getPoints(vid,\"hook wrong no defence\") \n",
    "# tmpl_2 = Template('hook wrong no defence', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#UPPER\n",
    "#uppercut correct\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\Traffic 2.mp4\"\n",
    "# vid = \"C:\\\\Users\\\\Abdelelah Hazem\\\\Downloads\\\\Traffic.mp4\"\n",
    "points = getPoints(vid,\"Traffic\") \n",
    "tmpl_2 = Template('Traffic', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "# #uppercut wrong (no torso & ankle  twist)\n",
    "# vid = \"C:\\Users\\omar3\\Pictures\\Camera Roll\\.mp4\"\n",
    "# points = getPoints(vid,\"uppercut wrong (no torso & ankle  twist)\") \n",
    "# tmpl_2 = Template('uppercut wrong (no torso & ankle  twist)', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "# #uppercut wrong no defence\n",
    "# vid = \"C:\\Users\\omar3\\Pictures\\Camera Roll\\.mp4\"\n",
    "# points = getPoints(vid,\"uppercut wrong no defence\") \n",
    "# tmpl_2 = Template('uppercut wrong no defence', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#right stroke wrong no defence\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\Bus 2.mp4\"\n",
    "# vid = \"C:\\\\Users\\\\Abdelelah Hazem\\\\Downloads\\\\Bus.mov\"\n",
    "points = getPoints(vid,\"Bus\") \n",
    "tmpl_2 = Template('Bus', points)\n",
    "templates.append(tmpl_2)\n",
    "\n",
    "# #right stroke wrong hand down no torso twist\n",
    "# vid = \"Dataset/right/(right) hand down no torso twist.mp4\"\n",
    "# points = getPoints(vid,\"(right) hand down no torso twist\") \n",
    "# tmpl_2 = Template('(right) hand down no torso twist', points)\n",
    "# templates.append(tmpl_2)\n",
    "# #right wrong  wrong return\n",
    "# vid = \"Dataset/right/(right) wrong return.mp4\"\n",
    "# points = getPoints(vid,\"(right) wrong return\") \n",
    "# tmpl_2 = Template('(right) wrong return', points)\n",
    "# templates.append(tmpl_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#right stroke wrong no defence\n",
    "vid = \"C:\\\\Users\\\\omar3\\\\Downloads\\\\Compressed\\\\HCI-Traffic-Guidance\\\\Gestures\\\\gestures videos\\\\Train.mp4\"\n",
    "# vid = \"c:\\\\Users\\Abdelelah Hazem\\\\Downloads\\\\Train.mp4\"\n",
    "points = getPoints(vid,\"Train\") \n",
    "tmpl_2 = Template('Train', points)\n",
    "templates.append(tmpl_2)\n",
    "#save_templates(templates)\n",
    "#[]\n",
    "# #right stroke wrong hand down no torso twist\n",
    "# vid = \"Dataset/right/(right) hand down no torso twist.mp4\"\n",
    "# points = getPoints(vid,\"(right) hand down no torso twist\") \n",
    "# tmpl_2 = Template('(right) hand down no torso twist', points)\n",
    "# templates.append(tmpl_2)\n",
    "# #right wrong  wrong return\n",
    "# vid = \"Dataset/right/(right) wrong return.mp4\"\n",
    "# points = getPoints(vid,\"(right) wrong return\") \n",
    "# tmpl_2 = Template('(right) wrong return', points)\n",
    "# templates.append(tmpl_2)\n",
    "recognizer = Recognizer(templates)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3cd79e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "262e1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testpoints():\n",
    "    cap = cv2.VideoCapture(1)#web cam =0 , else enter filename\n",
    "    # Initiate holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        points = []\n",
    "        wrist = []\n",
    "        Thumb_cmc=[]\n",
    "        Thumb_mcp=[]\n",
    "        Thumb_ip=[]\n",
    "        Thumb_tip=[]\n",
    "        Index_finger_mcp=[]\n",
    "        Index_finger_pip=[]\n",
    "        Index_finger_dip=[]\n",
    "        Index_finger_tip=[]\n",
    "        Middle_finger_mcp=[]\n",
    "        Middle_finger_pip=[]\n",
    "        Middle_finger_dip=[]\n",
    "        Middle_finger_tip=[]\n",
    "        Ring_finger_mcp=[]\n",
    "        Ring_finger_pip=[]\n",
    "        Ring_finger_dip=[]\n",
    "        Ring_finger_tip=[]\n",
    "        Pinky_mcp=[]\n",
    "        Pinky_pip=[]\n",
    "        Pinky_dip=[]\n",
    "        Pinky_tip=[]   \n",
    "\n",
    "        while cap.isOpened():\n",
    "            # time.sleep(0.2)\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor Feed\n",
    "            if ret==True:\n",
    "\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False        \n",
    "\n",
    "                # Make Detections\n",
    "                results = holistic.process(image)\n",
    "                # print(results.face_landmarks)\n",
    "\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Drawing on Frame (You can remove it)\n",
    "                # 2. Right hand\n",
    "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                # # 4. Pose Detections\n",
    "                # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                # # Export coordinates\n",
    "\n",
    "                try:\n",
    "\n",
    "                    # add points of wrist , elbow and shoulder\n",
    "                    wrist.append(Point(results.pose_landmarks.landmark[0].x,results.pose_landmarks.landmark[0].y,1))\n",
    "                    Thumb_cmc.append(Point(results.pose_landmarks.landmark[1].x,results.pose_landmarks.landmark[1].y,1))\n",
    "                    Thumb_mcp.append(Point(results.pose_landmarks.landmark[2].x,results.pose_landmarks.landmark[2].y,1))\n",
    "                    Thumb_ip .append(Point(results.pose_landmarks.landmark[3].x,results.pose_landmarks.landmark[3].y,1))\n",
    "                    Thumb_tip .append(Point(results.pose_landmarks.landmark[4].x,results.pose_landmarks.landmark[4].y,1))\n",
    "                    Index_finger_mcp.append(Point(results.pose_landmarks.landmark[5].x,results.pose_landmarks.landmark[5].y,1))\n",
    "                    Index_finger_pip.append(Point(results.pose_landmarks.landmark[6].x,results.pose_landmarks.landmark[6].y,1))\n",
    "                    Index_finger_dip.append(Point(results.pose_landmarks.landmark[7].x,results.pose_landmarks.landmark[7].y,1))\n",
    "                    Index_finger_tip.append(Point(results.pose_landmarks.landmark[8].x,results.pose_landmarks.landmark[8].y,1))\n",
    "                    Middle_finger_mcp.append(Point(results.pose_landmarks.landmark[9].x,results.pose_landmarks.landmark[9].y,1))\n",
    "                    Middle_finger_pip.append(Point(results.pose_landmarks.landmark[10].x,results.pose_landmarks.landmark[10].y,1))\n",
    "                    Middle_finger_dip.append(Point(results.pose_landmarks.landmark[11].x,results.pose_landmarks.landmark[11].y,1))\n",
    "                    Middle_finger_tip.append(Point(results.pose_landmarks.landmark[12].x,results.pose_landmarks.landmark[12].y,1))\n",
    "                    Ring_finger_mcp.append(Point(results.pose_landmarks.landmark[13].x,results.pose_landmarks.landmark[13].y,1))\n",
    "                    Ring_finger_pip.append(Point(results.pose_landmarks.landmark[14].x,results.pose_landmarks.landmark[14].y,1))\n",
    "                    Ring_finger_dip.append(Point(results.pose_landmarks.landmark[15].x,results.pose_landmarks.landmark[15].y,1))\n",
    "                    Ring_finger_tip.append(Point(results.pose_landmarks.landmark[16].x,results.pose_landmarks.landmark[16].y,1))\n",
    "                    Pinky_mcp.append(Point(results.pose_landmarks.landmark[17].x,results.pose_landmarks.landmark[17].y,1))\n",
    "                    Pinky_pip.append(Point(results.pose_landmarks.landmark[18].x,results.pose_landmarks.landmark[18].y,1))\n",
    "                    Pinky_dip.append(Point(results.pose_landmarks.landmark[19].x,results.pose_landmarks.landmark[19].y,1))\n",
    "                    Pinky_tip.append(Point(results.pose_landmarks.landmark[20].x,results.pose_landmarks.landmark[20].y,1))\n",
    "                    points = wrist + Thumb_cmc + Thumb_mcp + Thumb_ip + Thumb_tip + Index_finger_mcp + Index_finger_pip + Index_finger_dip + Index_finger_tip + Middle_finger_mcp + Middle_finger_pip + Middle_finger_dip + Middle_finger_tip + Ring_finger_mcp + Ring_finger_pip + Ring_finger_dip + Ring_finger_tip + Pinky_mcp + Pinky_pip + Pinky_dip + Pinky_tip\n",
    "                    result = recognizer.recognize(points)\n",
    "                    cv2.putText(image, f\"{result[0]} {result[1]}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                    # print(result)\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                cv2.imshow('aaa', image)\n",
    "            else :\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(100)\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(100)\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "testpoints()\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9d7620a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print all saved templates\n",
    "# print(\"\\nCurrent saved templates:\")\n",
    "# for template in templates:\n",
    "#     print(f\"Template Name: {template.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "95a45499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# cv2.VideoCapture(0, cv2.CAP_ANY)\n",
    "# while True:\n",
    "#     # Capture each frame from the camera\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         print(\"Error: Could not read frame from the camera.\")\n",
    "#         break\n",
    "#     points = getPoints(frame, \"Gestures\")\n",
    "#     if not points:\n",
    "#         print(\"Error: No points found.\")\n",
    "#     else:\n",
    "#         print(\"Points found:\", points)\n",
    "\n",
    "#     import time\n",
    "#     start = time.time()\n",
    "#     if templates:\n",
    "#         recognizer = Recognizer(templates)\n",
    "#         result = recognizer.recognize(points)\n",
    "#         end = time.time()\n",
    "#         print(result)\n",
    "#         print(\"Time taken to classify: \" + str(end - start))\n",
    "#     else:\n",
    "#         print(\"Error: templates are not initialized or empty.\")\n",
    "#     # Exit the loop if the 'q' key is pressed\n",
    "#     #     # Display the frame (optional)\n",
    "#     cv2.imshow(\"Camera Feed\", frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         print(\"Exiting...\")\n",
    "#         break\n",
    "\n",
    "#     # Release the camera and close any OpenCV windows\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f67f338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0bca825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Determine Points (Create empty list/s)\n",
    "# 2- Reshape Meidapipe format into Point Format (append to list)\n",
    "# 3- Record Dataset (3 Circle,3 Rectangle ,3 Square) via thumb\n",
    "# 3- Record Dataset (3 Circle,3 Rectangle ,3 Square) via index\n",
    "# 4- Training (2 samples for each class) via thumb\n",
    "# 4- Training (2 samples for each class) via index\n",
    "# 5- Testing (1 sample for each class) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
